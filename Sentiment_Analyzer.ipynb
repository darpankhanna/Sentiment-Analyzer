{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment-Analyzer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN6G3v0/15KgwMht8Huve5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darpankhanna/Sentiment-Analyzer/blob/main/Sentiment_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GdtuIWTXrvj"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from textblob import TextBlob\n",
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UfJ8Q-vY3NZ",
        "outputId": "c5c8b1b9-ab3b-4d67-d736-eeefc0d8c40b"
      },
      "source": [
        "# To read the dataset\n",
        "train =  pd.read_csv('/content/train.csv', nrows=7000)\n",
        "\n",
        "# To find the shape of the dataset\n",
        "train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "LXxwiWMbaICk",
        "outputId": "e4fba936-57dc-4a42-f575-7690db46b669"
      },
      "source": [
        "# Finding word count in each review\n",
        "train['word_count'] = train['text'].apply(lambda x: len(x.split()))\n",
        "train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I put this movie in my DVD player, and sa...</td>\n",
              "      <td>0</td>\n",
              "      <td>326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do people who do not know what a particula...</td>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Even though I have great interest in Biblical ...</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6995</th>\n",
              "      <td>A surprisingly effective thriller, this.&lt;br /&gt;...</td>\n",
              "      <td>1</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>Leave Ed Wood alone. To call \"Plan 9 from Oute...</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>This film is about a group of extra terrestria...</td>\n",
              "      <td>0</td>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>This program didn't do it for me, although I'm...</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>Family Guy is easily one of the worst shows I'...</td>\n",
              "      <td>0</td>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label  word_count\n",
              "0     I grew up (b. 1965) watching and loving the Th...      0         151\n",
              "1     When I put this movie in my DVD player, and sa...      0         326\n",
              "2     Why do people who do not know what a particula...      0         184\n",
              "3     Even though I have great interest in Biblical ...      0          69\n",
              "4     Im a die hard Dads Army fan and nothing will e...      1         178\n",
              "...                                                 ...    ...         ...\n",
              "6995  A surprisingly effective thriller, this.<br />...      1         215\n",
              "6996  Leave Ed Wood alone. To call \"Plan 9 from Oute...      0         174\n",
              "6997  This film is about a group of extra terrestria...      0         136\n",
              "6998  This program didn't do it for me, although I'm...      0         148\n",
              "6999  Family Guy is easily one of the worst shows I'...      0         161\n",
              "\n",
              "[7000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "Yhy5Jq5caqzH",
        "outputId": "f6f01846-3127-4118-d477-b2420d5432b6"
      },
      "source": [
        "# Calculate the Polarity of the Reviews\n",
        "def get_polarity(text):\n",
        "    textblob = TextBlob(str(text))\n",
        "    pol = textblob.sentiment.polarity\n",
        "    return pol\n",
        "\n",
        "train['polarity'] = train['text'].apply(get_polarity)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>word_count</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>0.123287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>When I put this movie in my DVD player, and sa...</td>\n",
              "      <td>0</td>\n",
              "      <td>326</td>\n",
              "      <td>0.131345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why do people who do not know what a particula...</td>\n",
              "      <td>0</td>\n",
              "      <td>184</td>\n",
              "      <td>-0.041369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Even though I have great interest in Biblical ...</td>\n",
              "      <td>0</td>\n",
              "      <td>69</td>\n",
              "      <td>-0.135714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0.123256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  polarity\n",
              "0  I grew up (b. 1965) watching and loving the Th...  ...  0.123287\n",
              "1  When I put this movie in my DVD player, and sa...  ...  0.131345\n",
              "2  Why do people who do not know what a particula...  ... -0.041369\n",
              "3  Even though I have great interest in Biblical ...  ... -0.135714\n",
              "4  Im a die hard Dads Army fan and nothing will e...  ...  0.123256\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIetb_LCa9EK"
      },
      "source": [
        "import string\n",
        "\n",
        "# Remove Punctuations from the Reviews\n",
        "def punctuation_removal(messy_str):\n",
        "    clean_list = [char for char in messy_str if char not in string.punctuation]\n",
        "    clean_str = ''.join(clean_list)\n",
        "    return clean_str\n",
        "\n",
        "train['text'] = train['text'].apply(punctuation_removal)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE9_dExAbDWj"
      },
      "source": [
        "# A function to remove Numbers from the reviews\n",
        "import re\n",
        "def drop_numbers(list_text):\n",
        "    list_text_new = []\n",
        "    for i in list_text:\n",
        "        if not re.search('\\d', i):\n",
        "            list_text_new.append(i)\n",
        "    return ''.join(list_text_new)\n",
        "\n",
        "train['text'] = train['text'].apply(drop_numbers)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGyfjPXCbGu2",
        "outputId": "9a56639d-7056-4d78-a666-256d8e0d4ca8"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOeMorBZicG_",
        "outputId": "e9e39dc4-7963-46b5-e65f-928d37012908"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNpVWTIlierW"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# for lemmatisation\n",
        "def lemmatise(text):\n",
        "    text_tokens = word_tokenize(text)\n",
        "    text_lemm = [lemmatizer.lemmatize(word.lower()) for word in text_tokens]\n",
        "    return ' '.join(text_lemm)\n",
        "\n",
        "train['text'] = train['text'].apply(lemmatise)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX59Mjko2BHx",
        "outputId": "de742f3a-afb6-4cdb-c5fc-12247ff38eca"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMRUd_es2FGe"
      },
      "source": [
        "# For Stopwords Removal\n",
        "from nltk.corpus import stopwords\n",
        "def remove_stopword(text):\n",
        "    text_tokens = word_tokenize(text)\n",
        "    tokens = [word for word in text_tokens if not word in set(stopwords.words('english'))]\n",
        "    tokens_text = ' '.join(tokens)\n",
        "    return tokens_text\n",
        "\n",
        "train['text'] = train['text'].apply(remove_stopword)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMaSCgzP2FMr",
        "outputId": "8ab86831-d334-4955-8a98-760ebe67450c"
      },
      "source": [
        "# TF-IDF Representation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tf = TfidfVectorizer(max_features = 3000)\n",
        "\n",
        "x = tf.fit_transform(train['text']).toarray()\n",
        "y = train.iloc[:, 1].values\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7000, 3000)\n",
            "(7000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQwxGwRw3BzW",
        "outputId": "f519e4df-e226-4af2-cb95-64ac9ccf2651"
      },
      "source": [
        "#Splitting the data into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 15)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4900, 3000)\n",
            "(4900,)\n",
            "(2100, 3000)\n",
            "(2100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHCzdpWx3GHD",
        "outputId": "ebc2f9f0-3ac3-4a95-a621-f8fbd1dad2db"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "print(\"Training Accuracy :\", model.score(x_train, y_train))\n",
        "print(\"Testing Accuracy :\", model.score(x_test, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy : 0.8771428571428571\n",
            "Testing Accuracy : 0.7657142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DxmoQHI3RQP",
        "outputId": "1320b657-1e4d-4c13-e26c-7565b989bba1"
      },
      "source": [
        "from sklearn import metrics\n",
        "metrics.confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[811, 247],\n",
              "       [245, 797]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}